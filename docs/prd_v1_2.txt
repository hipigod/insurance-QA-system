demo-保险销售智能陪练系统-V1.2
文档信息
产品名称：保险销售智能陪练系统（暂定）
文档版本：v1.1 Demo版
创建日期：2025-12-30
产品阶段：Demo验证版

1. 需求背景
1.1 问题描述
保险行业销售人员在实际工作中面临以下挑战：
新人培训周期长：需要大量实际客户沟通经验积累，但真实客户资源有限。
实战机会少：新销售缺乏与不同类型客户沟通的经验。
产品知识掌握不足：保险产品条款复杂，难以快速熟悉并准确传达。
沟通技巧难以评估：缺乏客观、标准化的能力评估体系。
异议处理能力弱：面对客户质疑时应变能力不足。
1.2 目标用户
主要用户：
保险行业新人销售（0-6个月）
需要提升沟通技巧的在职销售人员
保险公司的培训部门
用户特征：
移动办公为主，使用手机时间超过80%。
需要灵活的练习时间（碎片化学习）。
对产品知识有学习需求，但缺乏系统性学习工具。
1.3 业务目标
短期目标（Demo阶段）：
验证AI陪练模式的有效性。
测试用户对智能评分的接受度。
收集用户反馈，优化产品方向。
长期目标（正式版）：
提升销售人员的客户沟通能力。
缩短新人培训周期30%以上。
建立标准化的销售能力评估体系。
真实案例总结制定陪练角色。
提高保险产品的销售转化率。

2. 产品定位
2.1 产品定义
本产品是一款面向保险销售人员的AI智能陪练平台，通过模拟真实客户对话场景，帮助销售人员提升沟通能力、产品知识和营销技巧，并提供AI驱动的多维度能力评估。
2.2 核心价值
随时练习：打破时间地点限制，利用碎片化时间进行模拟销售练习。
真实场景：AI模拟多种真实客户类型，提供接近真实的沟通体验。
智能评估：基于AI的多维度评分体系，客观评估销售能力。
快速提升：针对性的反馈和评价，帮助销售快速发现问题并改进。
知识巩固：通过练习加深对保险产品的理解和记忆。
2.3 产品差异化
2.4 技术优势
大模型驱动：利用国产大模型实现自然的对话交互和智能评估。
RAG技术：基于检索增强生成，确保AI回复的保险产品信息准确。
多模型支持：支持多种国产大模型，可根据需求灵活切换。
向量数据库：高效的产品知识库检索和匹配。

3. 用户故事
3.1 销售人员（主要用户）
故事1：新人小王的首次练习
"我刚加入保险公司2周，对产品还不够熟悉，也不知道该怎么跟客户沟通。我希望能找一个模拟客户练习一下，看看自己哪里需要改进。"
用户需求：
无需登录，直接开始练习。
选择简单一点的产品和客户类型。
练习后能看到详细的评分和建议。
了解自己在哪些方面还需要提升。
产品解决方案：
提供无需登录的快速开始入口。
预设"小白客户"等简单角色。
练习结束后展示多维度评分和评价。
提供具体的改进建议。
故事2：资深销售李经理的技能提升
"我已经做了3年保险销售了，但最近遇到很多难缠的客户，总是搞不定。我想练习一下如何应对这类客户，看看我的问题出在哪里。"
用户需求：
选择有挑战性的客户角色（如"难缠客户"）。
测试自己对产品的熟练程度。
了解自己在异议处理方面的表现。
查看历史练习记录，对比进步情况。
产品解决方案：
提供"难缠客户"、"懂行客户"等高难度角色。
异议处理能力专项识别和评估。
本地保存练习历史，支持查看对比。
针对性的改进建议。
3.2 管理员/培训师（次要用户）
故事3：培训师张老师的教学管理
"我需要为公司的新销售设置合适的练习场景和评分标准。希望能方便地配置客户角色特征、上传新的产品资料，并调整评分标准。"
用户需求：
后台管理界面。
配置客户角色的提示词。
上传产品文档（PDF/Word）。
设置和调整评分维度及权重。
配置AI模型的API Key。
产品解决方案：
提供后台管理系统。
角色提示词配置功能（角色特性通过Prompt控制）。
产品文档上传和向量化。
评分标准配置（可增减维度，支持动态权重配置）。
模型配置和切换功能。

4. 系统架构设计
4.1 整体架构
4.2 核心模块说明
4.2.1 前端模块
角色选择模块：展示可选客户角色列表。
产品选择模块：展示可选保险产品列表。
对话界面：实时聊天界面，展示对话历史。
评分报告：展示评分结果和AI评价。
4.2.2 后端服务模块
用户服务：管理用户会话和本地存储。
对话服务：处理实时对话，调用AI生成回复。
评分服务：对话结束后调用AI进行评分分析。
配置服务：管理后台配置（角色、评分标准、模型等）。
4.2.3 AI能力模块
对话生成：根据角色提示词和对话历史生成AI回复。
评分分析：根据评分标准提示词分析对话质量。
异议识别：识别客户异议类型（价格、信任、需求、竞品等）。
向量化服务：对上传的产品文档进行向量化处理。
4.3 人机交互节点
交互流程：
4.4 技术栈对比

5. 用户旅程
5.1 完整用户旅程
5.2 关键用户体验设计原则
移动优先：界面设计优先考虑移动端体验。
零门槛启动：无需登录注册，打开即用。
流畅对话：AI响应时间控制在3秒以内。
清晰反馈：评分报告直观易懂，提供具体改进建议。
本地存储：练习历史本地保存，保护隐私。

6. 系统工作流设计
6.1 传统流程 vs 智能工作流
传统培训流程：
AI智能陪练流程：
优势对比：
⏱️ 时间效率：从固定时间 → 随时随地
🎯 场景丰富度：从有限角色 → 无限组合
📊 反馈及时性：从事后点评 → 实时评估
🔄 练习频率：从定期培训 → 每日练习
6.2 完整系统工作流
6.3 各模块职责说明
6.4 关键时序流程
对话交互时序：
评分分析时序：

7. 功能清单
7.1 核心功能模块
7.1.1 用户端功能
F1. 场景选择
F1.1 浏览客户角色列表
展示角色名称、简介、难度等级
支持3-5种预置角色
F1.2 选择客户角色
单选，进入产品选择
F1.3 浏览产品列表
展示产品名称、简介
支持2-3款预置产品
F1.4 选择产品
单选，开始对话
F2. AI对话练习
F2.1 对话界面
聊天气泡式展示
区分用户消息和AI回复
滚动查看历史消息
F2.2 实时对话
用户输入文本消息
AI根据角色特征生成回复
响应时间 < 3秒
F2.3 对话控制
结束对话按钮
对话过程中可随时退出
F2.4 打字状态提示
AI思考时显示"正在输入..."
F3. 评分报告 (V1.1 增强)
F3.1 总分展示
百分制总分（0-100分）
分数等级展示（优秀/良好/合格/需改进）
F3.2 维度评分
沟通能力（0-100分）
有效营销（0-100分）
产品熟练度（0-100分）
异议处理能力（0-100分）
每个维度显示等级评语
F3.3 异议识别结果
展示识别到的异议类型标签
标签类型：价格异议、信任异议、需求异议、竞品异议等
显示各类型出现次数
F3.4 总体评价
AI生成的综合评语（200-300字）
包含优点分析和改进建议
F3.5 对话记录
完整对话历史展示
可滚动查看
F3.6 关键对话节点分析 (新增)
功能描述：识别并标记出对话中的关键节点（如开场白、需求挖掘、产品介绍、异议处理、促成尝试），并对这些节点的表现进行专项点评。
F3.7 优秀案例对比 (新增)
功能描述：在评分报告中，针对用户的薄弱环节，推送相关的“优秀对话片段”或“标准话术参考”，供用户对比学习。
F4. 历史记录
F4.1 练习列表
本地存储最近10条练习记录
显示时间、角色、产品、总分
F4.2 详情查看
点击查看历史评分报告
查看完整对话记录
F5. 数据持久化
F5.1 本地存储
使用浏览器LocalStorage
存储练习记录和对话历史
容量限制：最近10条记录
7.1.2 管理后台功能
F6. 角色配置
F6.1 角色列表管理
查看、新增、编辑、删除角色
F6.2 角色提示词配置
角色名称、描述
角色性格特征提示词
对话风格、行为模式
难度等级设置
说明：所有角色特性通过提示词（Prompt）进行控制，无需额外增加字段。
F6.3 角色预览
测试角色对话效果

F7. 评分标准配置 (V1.1 增强)
- F7.1 评分维度管理
  - 查看、新增、编辑、删除评分维度
  - Demo版默认4个维度
- F7.2 维度提示词配置
  - 维度名称、描述
  - 评分标准说明
  - 评分依据提示词
- F7.3 权重设置 (增强)
  - 功能描述：支持动态配置各评分维度的权重，以适应不同培训阶段（如新人侧重沟通，资深侧重异议处理）。
  - 默认：各维度权重相同（25%）。

F8. AI模型配置
- F8.1 模型列表
  - 支持的国产模型列表
  - 模型名称、供应商
- F8.2 API Key配置
  - 统一配置API Key
  - 支持多个模型Key
- F8.3 模型选择
  - 对话使用的模型
  - 评分使用的模型
- F8.4 模型测试
  - 测试模型连通性
  - 查看模型调用统计

F9. 系统配置
- F9.1 基础配置
  - 系统名称、Logo
  - 联系方式
- F9.2 对话参数配置
  - AI响应超时时间
  - 最大对话轮次
  - 温度参数等
- F9.3 数据管理
  - 清除本地缓存
  - 导出配置数据
  - 导入配置数据
7.2 智能化功能点
7.2.1 AI对话生成
功能描述：根据客户角色特征和产品信息，生成符合角色的自然对话回复。
智能点：
角色一致性：AI始终保持角色性格特征。
上下文理解：理解对话历史，生成连贯回复。
异议表达：自然地提出各种客户异议。
7.2.2 AI智能评分
功能描述：对完整对话进行多维度分析和评分。
智能点：
多维度评估：同时评估4个维度。
语义理解：理解对话内容的质量。
客观公正：基于提示词标准进行评分。
个性化评价：生成针对性的评价建议。
7.2.3 异议类型识别
功能描述：识别对话中客户提出的异议类型。
智能点：
多标签识别：识别多种异议类型。
上下文理解：结合上下文判断异议。
统计分析：统计各类型异议出现频率。
应对评估：评估用户对异议的应对效果。

8. 提示词/算法设计
8.1 客户角色生成提示词设计
角色定义提示词模板：
8.2 对话生成提示词设计
对话生成提示词模板：
8.3 评分标准提示词设计 
评分提示词模板：
8.4 异议识别提示词设计
异议识别提示词（已整合在评分提示词中）
异议类型定义：
价格异议：客户觉得保费太贵、不划算、性价比低。
信任异议：客户不信任保险公司、不相信销售、担心被骗。
需求异议：客户认为自己不需要保险、已经有了保障、不急于购买。
竞品异议：客户提到其他公司产品、对比竞品、觉得别家更好。
条款异议：客户对条款有疑问、觉得看不懂、担心有陷阱。
时机异议：客户表示现在不是时机、需要再考虑、要和家人商量。


9. 数据集要求
9.1 交互数据集
9.1.1 客户角色数据
Demo版数据需求：
预置3-5个客户角色。
每个角色包含：
角色基本信息（名称、类型、年龄、职业）。
性格特征描述（300-500字）。
沟通风格说明（200-300字）。
对保险的态度（200-300字）。
行为模式说明（300-500字）。
角色提示词（整合以上信息）。
数据来源：
由产品经理和销售培训师共同设计。
基于真实客户案例抽象提炼。
Demo版手动配置，正式版由AI生成。
9.1.2 保险产品数据
Demo版数据需求：
预置2-3款保险产品。
每个产品包含：
产品基本信息（名称、类型、保险公司）。
产品描述（200-300字）。
保障范围（详细说明）。
保费范围（价格区间）。
适用人群（目标客户）。
产品条款（详细文档）。
数据来源：
客户提供的真实产品文档（PDF/Word）。
产品手册、宣传材料。
Demo版手动上传配置。
9.2 输出质量数据
9.2.1 评分数据
数据结构：
总分（0-100整数）。
各维度分数（0-100整数）。
各维度评价文本（50-100字）。
异议类型标签数组。
总体评价文本（200-300字）。
关键节点点评（新增）。
优秀案例对比（新增）。
9.2.2 对话记录数据
数据结构：
会话ID。
角色ID。
产品ID。
对话时间戳。
对话轮次。
消息列表（角色、内容、时间）。
9.3 数据收集策略
9.3.1 Demo版数据收集
收集目的：
验证AI评分的准确性。
优化提示词效果。
收集用户反馈。
收集内容：
用户练习记录（本地存储）。
AI评分结果。
用户满意度反馈（可选）。
隐私保护：
Demo版数据仅存储在用户本地。
不上传到服务器。
不收集用户个人信息。

10. 测试标准
10.1 功能测试标准
10.1.1 对话功能测试
测试用例：
验收标准：
AI回复成功率 ≥ 95%。
角色一致性准确率 ≥ 90%（人工评估）。
响应时间达标率 ≥ 98%。
10.1.2 评分功能测试
测试用例：
验收标准：
AI评分与人工评分相关性 ≥ 0.7。
异议识别准确率 ≥ 85%。
评价内容满意度 ≥ 80%（用户反馈）。
10.1.3 后台配置测试
测试用例：
验收标准：
配置生效成功率 100%。
配置修改实时生效。
配置错误有明确提示。
10.2 性能测试标准
10.2.1 响应时间要求
10.2.2 并发性能要求（Demo版不要求）
Demo版为单机版本，不涉及并发性能。
10.3 用户体验测试标准
10.3.1 易用性测试
测试指标：
新用户首次使用成功率 ≥ 90%。
完成一次练习的平均时长 ≤ 10分钟。
用户任务完成率 ≥ 95%。
测试方法：
用户测试：5-10名用户试用。
观察用户操作路径。
收集用户困惑点。
10.3.2 满意度测试
测试指标：
AI回复自然度满意度 ≥ 75%（1-5分）。
评分准确性满意度 ≥ 70%（1-5分）。
整体满意度 ≥ 75%（1-5分）。
测试方法：
用户问卷调查。
访谈反馈。
10.4 线上监控指标（正式版）
Demo版暂不涉及线上部署和监控。

11. 异常处理与降级策略
11.1 异常场景定义
11.1.1 AI模型相关异常
11.1.2 系统相关异常
11.2 降级流程图
11.3 异常处理方案
11.3.1 AI调用失败处理
场景1：对话生成失败
场景2：评分生成失败
11.3.2 前端异常处理
网络异常：
显示"网络连接失败，请检查网络"。
提供重试按钮。
保存当前输入到草稿。
页面崩溃：
自动记录错误日志。
显示友好的错误页面。
提供刷新页面选项。
11.3.3 数据异常处理
本地存储失败：
数据库损坏：
检测到SQLite损坏时，提示用户。
自动重建数据库。
通知用户数据可能丢失。
11.4 用户友好的错误提示

12. 非功能性需求
12.1 性能需求
12.1.1 响应时间
12.1.2 资源占用
前端包大小：< 2MB（gzipped）。
内存占用：< 200MB。
本地存储空间：< 50MB。
12.1.3 可用性
系统可用率：≥ 99%（Demo版不严格要求）。
故障恢复时间：< 5分钟。
12.2 可用性需求
12.2.1 移动端适配
支持主流移动浏览器。
响应式设计，适配各种屏幕尺寸。
触摸操作友好。
软键盘适配良好。
12.2.2 易用性
无需学习即可开始使用。
操作流程简洁直观。
错误提示清晰友好。
支持常见浏览器（Chrome、Safari、微信浏览器）。
12.2.3 无障碍（Demo版可选）
适当的字体大小（≥ 14px）。
足够的点击区域（≥ 44x44px）。
清晰的视觉对比度。
12.3 安全需求
12.3.1 数据安全
Demo版：
API Key存储在本地，不暴露给前端。
对话记录仅存储在用户本地。
不收集用户个人信息。
12.3.2 访问控制
Demo版：
无需登录，不涉及权限控制。
12.3.3 内容安全
对话内容过滤（避免不当内容）。
防止恶意提示词注入。
产品信息准确性保障。
12.4 数据统计需求
12.4.1 Demo版统计
本地统计：
用户练习次数。
平均评分。
常用角色和产品。
（仅存储在本地，不上报）。

13. 迭代规划
13.1 MVP版本 (v1.1 Demo版)
13.1.1 版本目标
验证AI陪练模式的可行性。
测试用户接受度。
收集反馈用于产品优化。
13.1.2 功能范围
用户端：
✅ 3-5个客户角色选择。
✅ 2-3款保险产品选择。
✅ 文字对话交互。
✅ 4维度AI评分（沟通、营销、产品、异议处理）。
✅ 异议类型识别。
✅ 本地历史记录（最近10条）。
管理后台：
✅ 角色提示词配置。
✅ 评分标准配置（可增减维度）。
✅ 评分维度权重动态配置。
✅ 产品文档上传（PDF/Word）。
✅ AI模型配置（多模型切换、API Key）。
技术实现：
✅ Vue 3 前端 + FastAPI 后端。
✅ SQLite 数据库。
✅ ChromaDB 向量数据库。
✅ 国产大模型集成。
13.1.3 验收标准
AI对话响应时间 < 3秒。
AI评分与人工评分相关性 ≥ 0.7。
用户满意度 ≥ 75%。
系统稳定性 ≥ 95%。

14. 附录
14.1 术语表



文档变更记录
